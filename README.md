# Batch Connect - OSC Galaxy

An interactive app designed for OSC OnDemand that launches Galaxy
within an Owens batch job.

## Prerequisites

This Batch Connect app requires the following software be installed on the
**compute nodes** that the batch job is intended to run on (**NOT** the
OnDemand node):

- [Lmod] 6.0.1+ or any other `module restore` and `module load <modules>` based
  CLI used to load appropriate environments within the batch job before
  launching Galaxy.

[Lmod]: https://www.tacc.utexas.edu/research-development/tacc-projects/lmod

## Install

The Install process runs on the **login node**

Use git to clone this app and checkout the desired branch/version you want to
use:

```sh
git clone <repo>
cd <dir>
git checkout <tag/branch>
```

Install Galaxy and dependencies

```sh
sh install-galaxy.sh
```

You will not need to do anything beyond this as all necessary assets are
installed. You will also not need to restart this app as it isn't a Passenger
app.

To update the app you would:

```sh
cd <dir>
git fetch
git checkout <tag/branch>
```

Again, you do not need to restart the app as it isn't a Passenger app.

## Contributing

1. Fork it ( https://github.com/OSC/bc_osc_galaxy/fork )
2. Create your feature branch (`git checkout -b my-new-feature`)
3. Commit your changes (`git commit -am 'Add some feature'`)
4. Push to the branch (`git push origin my-new-feature`)
5. Create a new Pull Request

## Developer Notes

### Overview
Galaxy interface app runs on Owens. The users can install, manage and run tools and workflows.

### Changes
- [x] Remove galaxy submodule
- [x] Add install-galaxy.sh to install galaxy 19.09
- [x] Galaxy config files are removed and will be generated by before.sh.yml instead
- [x] Update Readme
- [x] Job Configuration. Currently, the jobs submitted via Galaxy will run on the same node as Galaxy.

### Known Issues:
- [ ] Get Data from external data sources
- [ ] Match workflow to destination
- [ ] The links in the sidebar and the main section are the same. The links in the sidebar are working but the links in the main section are broken. As the screenshot shows, the `admin/roles` is not correctly appended to the URL.
![broken link](https://user-images.githubusercontent.com/22674713/68046880-5bbd7800-fcb3-11e9-9b79-7f1d80a8306d.JPG)
- [ ] `pbs-python` is installed at run time when launching. 
```
Collecting pbs_python (from -r /dev/stdin (line 1))
Installing collected packages: pbs-python
Successfully installed pbs-python-4.4.2.1
```
may need to add something similiar to this to `install-galaxy.sh`
```
galaxy_user@galaxy_server% git clone https://github.com/ehiggs/pbs-python
galaxy_user@galaxy_server% cd pbs-python
galaxy_user@galaxy_server% source /clusterfs/galaxy/galaxy-app/.venv/bin/activate
galaxy_user@galaxy_server% python setup.py install
```
- [ ] When sharing the app, some files are trying to write to the galaxy.

## Experiment 1: Passenger App (failed)
Failed to mount the app to `/pun/dev/galaxy` due to 404 not found error.
## Experiment 2: Interactive App (succeed with known issues)
After git clone this repo, run `sh install-galaxy.sh` to git clone Galaxy release_19.09 to `./galaxy` folder and install dependencies in the virtual environment under `./galaxy.venv` folder and `_conda` under `./galaxy/database/dependencies` folder. This script will also build [custom visualization plugins](https://github.com/galaxyproject/galaxy/blob/dev/config/plugins/visualizations/README.txt)

After completing the `sh install-galaxy.sh`, galaxy can be launched as an interactive app. In `before.sh.erb`, `galaxy.yml` (general configuration), `job_resource_params_conf.xml` (job resource configuration for users to select), `job_conf.xml` (job runners configuration) are generated. 

Galaxy is mounted on [`/node/${HOSTNAME}/8080=galaxy.webapps.galaxy.buildapp:uwsgi_app()`](https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L115)

### Database: 
Data files are stored in the userâ€™s dataroot (default to `~/.galaxy/` configured in [Galaxy.yml](https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L124)

```
azhu $ ls ~/.galaxy/
citations  compiled_templates  control.sqlite  files  jobs_directory  object_store_cache  pbs  tmp  universe.sqlite
```

### Authentication: 
`Galaxy.yml` takes in the user email address as the user authentication in the single-user mode. User identification has to be in email format, so [`${USER}@osc.edu` is passed to `Galaxy.yml`](https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L125) as a temporary solution. Further authentication can be configured as described [here].(https://galaxyproject.org/admin/config/external-user-auth/)

### Select Job Runner
The users select the tool runner before starting the app. The developer adds destinations to job config file and assigns the user-selected runner to default.
https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L51-L62
Job runner field:
![form](https://user-images.githubusercontent.com/22674713/68041214-71787080-fca6-11e9-88a3-32f6c508c802.JPG)

### Three types of job runners we consider
#### 1. Run tools locally
#### Pros:
- tool jobs won't be queued and will run immediately

#### Cons:
- The number of concurrent jobs is limited, the maximum is the number of cores.
- When the session ends, the unfinished jobs will end too. 

#### 2. Submit tool jobs to the cluster
#### Pros:
- When the session ends, the unfinished jobs will continue to run.
- Unlimited number of concurrent jobs

#### Cons:
-  Galaxy can only submit the jobs to the same cluster Galaxy is running on. For now, we run Galaxy on Owens, It's not able to submit jobs to quick. Therefore, there's a waiting time for jobs to run.

#### 3. Users configure the runner before submitting each tool job. 
#### Pros:
- It's very configurable and flexible. We can configure different resources for different tools. 
The user can choose the default runner or specify resources:
![use default](https://user-images.githubusercontent.com/22674713/68044193-3a598d80-fcad-11e9-9331-255b5bea784d.JPG)
If the user chooses to specify resources:
 ![select params](https://user-images.githubusercontent.com/22674713/68043200-1e54ec80-fcab-11e9-928f-40747438946e.JPG)

#### Cons:
- Because we can configure different resources for different tools, we have to specify the resources for each tool in the job conf file. If the user installs new tools, we need to find a way to also add the configuration for the new tools to the job conf file. 
- Because the resource selection is part of the tool form, for tools without tool forms like tools under `GET DATA`  section, the users can't specify resources.

## Example: configure dynamic running tools with user-defined resources 
As an example, I configured BED-to-GFF tool to provide resources selection fields. Steps to configure a tool to use the dynamic runner based on resource parameters selected by the user:
         1. Specify the parameters in the job resource configuration file (https://github.com/galaxyproject/galaxy/blob/dev/lib/galaxy/config/sample/job_resource_params_conf.xml.sample). The following example contains `cores` and `walltime`. The input field can be an input box or a dropdown with several options.
https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L67-L76
        2.  Add rules to https://github.com/galaxyproject/galaxy/tree/dev/lib/galaxy/jobs/rules directory to match job resource parameters entered by the user to destinations. The following example matches the default runner to the default destination. If the user enters cores and walltime, we construct a resource list and run the tool with pbs runner. 
https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/install-galaxy.sh#L11-L43
         3. Add dynamic job runner to the `<plugins>` in job config file. `rules_module` field indicates the location of the files we created at step 2. https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L47-L49
         4. Inside of `<resources>`  in the job config file, add a group of parameters we defined at step 1 and define the group id. https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L38-L40
       5.  Inside of `<tools>`  in the job config file, specify the id="tool_id", destination="destination_id" and resource="resource_group_id" https://github.com/OSC/bc_osc_galaxy/blob/9afb0b7ec7452261149290cec5fb7d2d00b4c958/template/before.sh.erb#L41-L43

Tools are defined under `https://github.com/galaxyproject/galaxy/tree/dev/tools` in the xml files. To find tool id, it's defined in the `<tool>` tag such as `<tool id="createInterval" name="Create single interval" version="1.0.0">`.
